Resources
==========


Software
--------------------

- Spearmint (GP-EI): https://github.com/JasperSnoek/spearmint
- Hyperopt (TPE): https://github.com/hyperopt/hyperopt
- SMAC: https://github.com/automl/SMAC3
- TPOP (AutoML based on genetic programming): https://github.com/EpistasisLab/tpot
- Bayesian optimization in PyTorch: https://github.com/pytorch/botorch
- HPOlib (another common interface to three BO methods): https://github.com/automl/HPOlib
- skopt (several methods for sequential model-based optimization): https://scikit-optimize.github.io
- auto-sklearn (Automated Machine Learning with scikit-learn): https://github.com/automl/auto-sklearn
- autokeras (AutoML for deep learning): https://github.com/keras-team/autokeras
- pyautoweka (AutoWeka in python): https://github.com/automl/pyautoweka

To be added ...

Reference
----------

.. [Bergstra2011] Bergstra J. S., Bardenet R., Bengio Y. and Kégl B. (2011). Algorithms for hyper-parameter optimization. In Advances in Neural Information Processing Systems, pp. 2546-2554.

.. [Bergstra2012] Bergstra J. and Bengio Y. (2012). Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb): 281-305.

.. [Fang1980] Fang, K.T. (1980). The uniform design: application of number theoretic methods in experimental design. Acta Math. Appl. Sin. 3:363-372.

.. [Hutter2011] Hutter F., Hoos H.H. and Leyton-Brown K. (2011) Sequential model-based optimization for general algorithm configuration. In International Conference on Learning and Intelligent Optimization, pp. 507-523. Springer.

.. [McKay1978] McKay, M.D., Beckman, R.J. and Conover, W.J. (1979). Comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 21(2): 239-245.

.. [Sobol967] Sobol,I.M. (1967), Distribution of points in a cube and approximate evaluation of integrals. Zh. Vych. Mat. Mat. Fiz. 7: 784-802 (in Russian); U.S.S.R Comput. Maths. Math. Phys. 7: 86-112 (in English).

.. [Snoek2012] Snoek J., Larochelle H. and Adams R.P. (2012). Practical bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems, pp. 2951–2959.

.. [Wang1981] Wang, Y. and Fang, K.T. (1981). A note on uniform distribution and experimental design. Kexue Tongbao 26, 485-489.

.. [Yang2019] Yang Z. B. and Zhang A.J. (2021). Hyperparameter Optimization via Sequential Uniform Designs. Journal of Machine Learning Research, 22(149), pp.1-47.
